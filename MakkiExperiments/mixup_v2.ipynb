{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mixup_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ryhgc3gxxIcT",
        "TJCHkouWM-nU",
        "mW3c_y7HxpQV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc3586442b344eb782295c66a310bfe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e8ca6b47bce4962ae29720661e968f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f95a310e10ea42d58b2223d4792f114a",
              "IPY_MODEL_e7c657b6782e48dab0b18f28273abc9e"
            ]
          }
        },
        "7e8ca6b47bce4962ae29720661e968f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f95a310e10ea42d58b2223d4792f114a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36626668cee04a4a87144cca3ab5c448",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c2c312318a740c98e1a2c463a38f48f"
          }
        },
        "e7c657b6782e48dab0b18f28273abc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa7d68db10794bc68ba90f451fbd0097",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [1:01:02&lt;00:00, 46558.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b597026986248e5b2996a1be3f43d10"
          }
        },
        "36626668cee04a4a87144cca3ab5c448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c2c312318a740c98e1a2c463a38f48f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa7d68db10794bc68ba90f451fbd0097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b597026986248e5b2996a1be3f43d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6P3C1jXM57-"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9RQ_TZoHmvs",
        "outputId": "081f794a-0873-42ca-c97c-a6c9e1af70c3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Feb 20 10:22:14 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYQJsgV5xfnf",
        "outputId": "a21b218e-b0ad-4f87-8b85-ff49d31ac03d"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezqHytvHH_yK",
        "outputId": "5d4ed1d7-af38-4044-b8b7-aaab2e65e767"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: MohamedAlmaki\n",
            "Password: ··········\n",
            "Repo name: segmix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryhgc3gxxIcT"
      },
      "source": [
        "# Mixup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3T3GH_kzoUV"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np \n",
        "import csv\n",
        "from enum import Enum\n",
        "from segmix.models import Model, load_model, save_checkpoint, load_checkpoint\n",
        "from segmix.datasets import Dataset, getTransfroms, getDatasetLoaders\n",
        "from segmix.train import MixTrainer, MixTester\n",
        "from segmix.mix import Mixup\n",
        "from segmix.logger import CSVLogger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bc3586442b344eb782295c66a310bfe3",
            "7e8ca6b47bce4962ae29720661e968f9",
            "f95a310e10ea42d58b2223d4792f114a",
            "e7c657b6782e48dab0b18f28273abc9e",
            "36626668cee04a4a87144cca3ab5c448",
            "9c2c312318a740c98e1a2c463a38f48f",
            "aa7d68db10794bc68ba90f451fbd0097",
            "7b597026986248e5b2996a1be3f43d10"
          ]
        },
        "id": "SBlPSPCFEajS",
        "outputId": "352bc98e-d151-4c35-b576-3a67e69ff9a5"
      },
      "source": [
        "def main(): \n",
        "    device = \"cuda\"\n",
        "    resume = True\n",
        "    mpath = \"/content/drive/MyDrive/segmix/mixup_resnet18_100.pth\"\n",
        "    logpath = \"/content/drive/MyDrive/segmix/mixup_resnet18_100_log.csv\"\n",
        "    dpath = \".\"\n",
        "    \n",
        "    model = load_model(Model.resnet18).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9, weight_decay=1e-4)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,78,eta_min=0.001)\n",
        "    mixmethod = Mixup(0.3, device)\n",
        "    epochs = 100\n",
        "    best_acc, s_epoch = 0, 0\n",
        "    \n",
        "    if resume: \n",
        "        print(\"Resuming from the last checkpoint...\")\n",
        "        model, optimizer, s_epoch, best_acc = load_checkpoint(mpath, model, optimizer)\n",
        "        print(s_epoch)\n",
        "        print(best_acc)\n",
        "\n",
        "    train_transforms, test_transforms = getTransfroms()\n",
        "    trainset, trainloader, testset, testloader, classes = getDatasetLoaders(Dataset.cifar10, dpath, train_transforms, test_transforms)\n",
        "    \n",
        "    trainer = MixTrainer(model, trainloader, criterion, optimizer, mixmethod, lr_scheduler=lr_scheduler, device=device)\n",
        "    tester = MixTester(model, criterion, testloader, device=device)\n",
        "    logger = CSVLogger(logpath, ['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n",
        "    \n",
        "    for epoch in range(s_epoch +  1, epochs):\n",
        "        train_loss, train_acc = trainer.train(epoch)\n",
        "        test_loss, test_acc = tester.test(epoch)\n",
        "        \n",
        "        if(test_acc > best_acc): \n",
        "            best_acc = test_acc\n",
        "            print(\"Saving...\")\n",
        "            save_checkpoint(model, mpath, optimizer, epoch, best_acc)\n",
        "            \n",
        "        logger.log([epoch, train_loss, train_acc, test_loss, test_acc])\n",
        "            \n",
        "if __name__ == \"__main__\": \n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resuming from the last checkpoint...\n",
            "11\n",
            "63.59000015258789\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc3586442b344eb782295c66a310bfe3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 12\n",
            "Loss: 1.4059983073136746| Acc: 53.7077522277832 (26810.91015625/49920)\n",
            "Loss: 1.407371768951416| Acc: 59.630001068115234 (5963/10000)\n",
            "\n",
            "Epoch: 13\n",
            "Loss: 1.3805257708598406| Acc: 54.57643127441406 (27244.5546875/49920)\n",
            "Loss: 0.992950576543808| Acc: 66.13999938964844 (6614/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 14\n",
            "Loss: 1.3552854916988275| Acc: 55.47130584716797 (27691.275390625/49920)\n",
            "Loss: 0.9737862998247147| Acc: 66.16999816894531 (6617/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "Loss: 1.3712933702346606| Acc: 55.2291374206543 (27570.384765625/49920)\n",
            "Loss: 1.0893539214134216| Acc: 63.34000015258789 (6334/10000)\n",
            "\n",
            "Epoch: 16\n",
            "Loss: 1.3051165070289221| Acc: 57.14855194091797 (28528.556640625/49920)\n",
            "Loss: 1.0899423891305924| Acc: 68.01000213623047 (6801/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 17\n",
            "Loss: 1.289427431424459| Acc: 58.30710983276367 (29106.91015625/49920)\n",
            "Loss: 0.9247118318080902| Acc: 69.3499984741211 (6935/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 18\n",
            "Loss: 1.3043782879144719| Acc: 57.65080261230469 (28779.279296875/49920)\n",
            "Loss: 0.9153898668289184| Acc: 69.68000030517578 (6968/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 19\n",
            "Loss: 1.23897822422859| Acc: 59.687198638916016 (29795.849609375/49920)\n",
            "Loss: 1.062831859588623| Acc: 65.77999877929688 (6578/10000)\n",
            "\n",
            "Epoch: 20\n",
            "Loss: 1.2079659434465262| Acc: 60.82609558105469 (30364.38671875/49920)\n",
            "Loss: 0.8639755403995514| Acc: 70.44000244140625 (7044/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 21\n",
            "Loss: 1.2497427594967379| Acc: 59.7915153503418 (29847.923828125/49920)\n",
            "Loss: 0.8814645487070084| Acc: 72.16000366210938 (7216/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 22\n",
            "Loss: 1.2575528346575224| Acc: 59.19493103027344 (29550.109375/49920)\n",
            "Loss: 0.8307096087932586| Acc: 72.26000213623047 (7226/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 23\n",
            "Loss: 1.203948556765532| Acc: 61.00289535522461 (30452.64453125/49920)\n",
            "Loss: 0.975886902809143| Acc: 67.43000030517578 (6743/10000)\n",
            "\n",
            "Epoch: 24\n",
            "Loss: 1.224384775222876| Acc: 60.67195129394531 (30287.4375/49920)\n",
            "Loss: 0.94855024933815| Acc: 68.83999633789062 (6884/10000)\n",
            "\n",
            "Epoch: 25\n",
            "Loss: 1.1521163567518578| Acc: 62.99026107788086 (31444.736328125/49920)\n",
            "Loss: 0.7435228651762009| Acc: 75.58000183105469 (7558/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 26\n",
            "Loss: 1.1924379920348143| Acc: 61.677555084228516 (30789.435546875/49920)\n",
            "Loss: 0.7930797737836838| Acc: 74.97000122070312 (7497/10000)\n",
            "\n",
            "Epoch: 27\n",
            "Loss: 1.1750958681106567| Acc: 62.6201171875 (31259.962890625/49920)\n",
            "Loss: 0.9445168542861938| Acc: 70.86000061035156 (7086/10000)\n",
            "\n",
            "Epoch: 28\n",
            "Loss: 1.1699679545867137| Acc: 63.15778350830078 (31528.365234375/49920)\n",
            "Loss: 0.845271025300026| Acc: 74.0199966430664 (7402/10000)\n",
            "\n",
            "Epoch: 29\n",
            "Loss: 1.1496047356189825| Acc: 63.68418502807617 (31791.14453125/49920)\n",
            "Loss: 0.7457964438199997| Acc: 76.31999969482422 (7632/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 30\n",
            "Loss: 1.1258288047252558| Acc: 64.27510070800781 (32086.130859375/49920)\n",
            "Loss: 0.7351622238755227| Acc: 76.19000244140625 (7619/10000)\n",
            "\n",
            "Epoch: 31\n",
            "Loss: 1.1298259258270265| Acc: 63.915626525878906 (31906.6796875/49920)\n",
            "Loss: 0.834226261973381| Acc: 73.58000183105469 (7358/10000)\n",
            "\n",
            "Epoch: 32\n",
            "Loss: 1.0926795186140599| Acc: 65.73966979980469 (32817.2421875/49920)\n",
            "Loss: 0.7198327246308327| Acc: 76.22000122070312 (7622/10000)\n",
            "\n",
            "Epoch: 33\n",
            "Loss: 1.1293193004070183| Acc: 64.47388458251953 (32185.365234375/49920)\n",
            "Loss: 0.6991472202539444| Acc: 77.4000015258789 (7740/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 34\n",
            "Loss: 1.1055638851263585| Acc: 65.19036102294922 (32543.03125/49920)\n",
            "Loss: 0.7062809360027313| Acc: 77.70999908447266 (7771/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 35\n",
            "Loss: 1.0988001878444964| Acc: 65.5837631225586 (32739.416015625/49920)\n",
            "Loss: 0.9676126515865326| Acc: 71.2699966430664 (7127/10000)\n",
            "\n",
            "Epoch: 36\n",
            "Loss: 1.1225158342948327| Acc: 64.5152359008789 (32206.005859375/49920)\n",
            "Loss: 0.7064713367819786| Acc: 76.45999908447266 (7646/10000)\n",
            "\n",
            "Epoch: 37\n",
            "Loss: 1.0659328793868041| Acc: 66.4052963256836 (33149.5234375/49920)\n",
            "Loss: 0.6406698712706566| Acc: 79.16000366210938 (7916/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 38\n",
            "Loss: 1.0135378615978436| Acc: 68.17549896240234 (34033.2109375/49920)\n",
            "Loss: 0.6536185312271118| Acc: 78.36000061035156 (7836/10000)\n",
            "\n",
            "Epoch: 39\n",
            "Loss: 1.0899771502384772| Acc: 65.57456970214844 (32734.82421875/49920)\n",
            "Loss: 0.8288212656974793| Acc: 72.73999786376953 (7274/10000)\n",
            "\n",
            "Epoch: 40\n",
            "Loss: 1.035066257378994| Acc: 67.6453857421875 (33768.57421875/49920)\n",
            "Loss: 0.7244877630472183| Acc: 76.54000091552734 (7654/10000)\n",
            "\n",
            "Epoch: 41\n",
            "Loss: 1.0920172379567072| Acc: 65.43135833740234 (32663.333984375/49920)\n",
            "Loss: 0.6760371798276901| Acc: 78.75 (7875/10000)\n",
            "\n",
            "Epoch: 42\n",
            "Loss: 1.0587159000910245| Acc: 67.09906005859375 (33495.8515625/49920)\n",
            "Loss: 0.6346640747785568| Acc: 79.22000122070312 (7922/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 43\n",
            "Loss: 1.0332108601545675| Acc: 67.92870330810547 (33910.0078125/49920)\n",
            "Loss: 0.8288172423839569| Acc: 72.87000274658203 (7287/10000)\n",
            "\n",
            "Epoch: 44\n",
            "Loss: 0.9897883905814244| Acc: 68.90599822998047 (34397.875/49920)\n",
            "Loss: 0.6573529925942421| Acc: 78.5199966430664 (7852/10000)\n",
            "\n",
            "Epoch: 45\n",
            "Loss: 1.0077746839095385| Acc: 68.89289855957031 (34391.3359375/49920)\n",
            "Loss: 0.6253275474905968| Acc: 80.12999725341797 (8013/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 46\n",
            "Loss: 0.9880151932056134| Acc: 69.29888153076172 (34594.0/49920)\n",
            "Loss: 0.6548254835605621| Acc: 78.41000366210938 (7841/10000)\n",
            "\n",
            "Epoch: 47\n",
            "Loss: 1.051669924839949| Acc: 66.8707504272461 (33381.87890625/49920)\n",
            "Loss: 0.886445095539093| Acc: 70.63999938964844 (7064/10000)\n",
            "\n",
            "Epoch: 48\n",
            "Loss: 1.0814470642652267| Acc: 65.9619140625 (32928.1875/49920)\n",
            "Loss: 0.6781314072012902| Acc: 77.16000366210938 (7716/10000)\n",
            "\n",
            "Epoch: 49\n",
            "Loss: 1.0678076141919846| Acc: 66.71993255615234 (33306.58984375/49920)\n",
            "Loss: 0.6370178145170212| Acc: 80.19000244140625 (8019/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 50\n",
            "Loss: 1.030130719832885| Acc: 68.40325164794922 (34146.90234375/49920)\n",
            "Loss: 0.6131303575634957| Acc: 79.88999938964844 (7989/10000)\n",
            "\n",
            "Epoch: 51\n",
            "Loss: 1.0352807317024622| Acc: 67.98989868164062 (33940.55859375/49920)\n",
            "Loss: 0.6716407817602158| Acc: 78.81999969482422 (7882/10000)\n",
            "\n",
            "Epoch: 52\n",
            "Loss: 0.999595779639024| Acc: 68.96868133544922 (34429.1640625/49920)\n",
            "Loss: 0.6728079530596733| Acc: 78.02999877929688 (7803/10000)\n",
            "\n",
            "Epoch: 53\n",
            "Loss: 1.0342798297221845| Acc: 68.00960540771484 (33950.39453125/49920)\n",
            "Loss: 0.6103381130099297| Acc: 80.51000213623047 (8051/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 54\n",
            "Loss: 1.0147220512231192| Acc: 68.3289794921875 (34109.828125/49920)\n",
            "Loss: 0.5758026587963104| Acc: 81.20999908447266 (8121/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 55\n",
            "Loss: 1.0442864135289804| Acc: 67.38484191894531 (33638.51171875/49920)\n",
            "Loss: 0.7145443981885911| Acc: 76.83999633789062 (7684/10000)\n",
            "\n",
            "Epoch: 56\n",
            "Loss: 1.0138016871916942| Acc: 68.72689056396484 (34308.46484375/49920)\n",
            "Loss: 0.6824886673688888| Acc: 78.30999755859375 (7831/10000)\n",
            "\n",
            "Epoch: 57\n",
            "Loss: 1.0258119242313581| Acc: 68.19556427001953 (34043.2265625/49920)\n",
            "Loss: 0.6079831483960152| Acc: 81.0999984741211 (8110/10000)\n",
            "\n",
            "Epoch: 58\n",
            "Loss: 0.9937647692668132| Acc: 69.00890350341797 (34449.24609375/49920)\n",
            "Loss: 0.5854733318090439| Acc: 81.16999816894531 (8117/10000)\n",
            "\n",
            "Epoch: 59\n",
            "Loss: 0.9673608371844659| Acc: 70.3161849975586 (35101.83984375/49920)\n",
            "Loss: 0.7513883522152901| Acc: 74.48999786376953 (7449/10000)\n",
            "\n",
            "Epoch: 60\n",
            "Loss: 1.0123695171796359| Acc: 68.9603042602539 (34424.984375/49920)\n",
            "Loss: 0.6714554032683373| Acc: 79.02999877929688 (7903/10000)\n",
            "\n",
            "Epoch: 61\n",
            "Loss: 0.9048004026596362| Acc: 72.212646484375 (36048.5546875/49920)\n",
            "Loss: 0.5695999252796173| Acc: 81.79000091552734 (8179/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 62\n",
            "Loss: 0.9679003004844372| Acc: 69.98927307128906 (34938.64453125/49920)\n",
            "Loss: 0.5925787562131881| Acc: 81.75 (8175/10000)\n",
            "\n",
            "Epoch: 63\n",
            "Loss: 0.9831107316873012| Acc: 69.36564636230469 (34627.33203125/49920)\n",
            "Loss: 0.6521531429886818| Acc: 78.43000030517578 (7843/10000)\n",
            "\n",
            "Epoch: 64\n",
            "Loss: 0.9781025955310234| Acc: 69.8655014038086 (34876.859375/49920)\n",
            "Loss: 0.6188187032938004| Acc: 80.18000030517578 (8018/10000)\n",
            "\n",
            "Epoch: 65\n",
            "Loss: 0.9880041622198545| Acc: 69.75457000732422 (34821.48046875/49920)\n",
            "Loss: 0.56310148447752| Acc: 81.91000366210938 (8191/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 66\n",
            "Loss: 0.9561187354417947| Acc: 70.94505310058594 (35415.76953125/49920)\n",
            "Loss: 0.5778186085820198| Acc: 81.08000183105469 (8108/10000)\n",
            "\n",
            "Epoch: 67\n",
            "Loss: 0.9466056874165168| Acc: 70.77058410644531 (35328.67578125/49920)\n",
            "Loss: 0.6930736288428306| Acc: 76.83000183105469 (7683/10000)\n",
            "\n",
            "Epoch: 68\n",
            "Loss: 0.943976662097833| Acc: 70.99359893798828 (35440.00390625/49920)\n",
            "Loss: 0.5989823347330093| Acc: 80.23999786376953 (8024/10000)\n",
            "\n",
            "Epoch: 69\n",
            "Loss: 0.8984422167142232| Acc: 72.49054718017578 (36187.28125/49920)\n",
            "Loss: 0.5592986333370209| Acc: 81.9000015258789 (8190/10000)\n",
            "\n",
            "Epoch: 70\n",
            "Loss: 0.9219644228617351| Acc: 71.81393432617188 (35849.515625/49920)\n",
            "Loss: 0.5759894144535065| Acc: 82.01000213623047 (8201/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 71\n",
            "Loss: 0.8919226109981537| Acc: 72.7413330078125 (36312.47265625/49920)\n",
            "Loss: 0.6486929807066918| Acc: 78.52999877929688 (7853/10000)\n",
            "\n",
            "Epoch: 72\n",
            "Loss: 0.9969132281266726| Acc: 69.29826354980469 (34593.69140625/49920)\n",
            "Loss: 0.6019914814829826| Acc: 80.55999755859375 (8056/10000)\n",
            "\n",
            "Epoch: 73\n",
            "Loss: 0.9955576911950723| Acc: 68.97891235351562 (34434.2734375/49920)\n",
            "Loss: 0.560642668902874| Acc: 82.08999633789062 (8209/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 74\n",
            "Loss: 0.9444973393892631| Acc: 71.13642883300781 (35511.3046875/49920)\n",
            "Loss: 0.5622740411758422| Acc: 81.93000030517578 (8193/10000)\n",
            "\n",
            "Epoch: 75\n",
            "Loss: 0.9198176466501676| Acc: 72.279541015625 (36081.9453125/49920)\n",
            "Loss: 0.6063811787962914| Acc: 80.05000305175781 (8005/10000)\n",
            "\n",
            "Epoch: 76\n",
            "Loss: 0.9309935401647519| Acc: 71.45779418945312 (35671.73046875/49920)\n",
            "Loss: 0.5802570521831513| Acc: 80.9000015258789 (8090/10000)\n",
            "\n",
            "Epoch: 77\n",
            "Loss: 0.8887038104045085| Acc: 72.73819732666016 (36310.91015625/49920)\n",
            "Loss: 0.518345792889595| Acc: 83.01000213623047 (8301/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 78\n",
            "Loss: 0.9085581061167595| Acc: 72.2378921508789 (36061.15625/49920)\n",
            "Loss: 0.5282760909199715| Acc: 82.79000091552734 (8279/10000)\n",
            "\n",
            "Epoch: 79\n",
            "Loss: 0.9314986442908263| Acc: 71.926025390625 (35905.47265625/49920)\n",
            "Loss: 0.6300351744890214| Acc: 80.16999816894531 (8017/10000)\n",
            "\n",
            "Epoch: 80\n",
            "Loss: 0.9313332782341883| Acc: 71.38308715820312 (35634.4375/49920)\n",
            "Loss: 0.5776990529894829| Acc: 80.91999816894531 (8092/10000)\n",
            "\n",
            "Epoch: 81\n",
            "Loss: 0.8975729888830429| Acc: 72.90123748779297 (36392.296875/49920)\n",
            "Loss: 0.5185528963804245| Acc: 83.27999877929688 (8328/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 82\n",
            "Loss: 0.9197722101822877| Acc: 71.99925231933594 (35942.02734375/49920)\n",
            "Loss: 0.5363178333640098| Acc: 82.54000091552734 (8254/10000)\n",
            "\n",
            "Epoch: 83\n",
            "Loss: 0.9266442716121673| Acc: 71.72796630859375 (35806.6015625/49920)\n",
            "Loss: 0.5906825375556946| Acc: 80.12999725341797 (8013/10000)\n",
            "\n",
            "Epoch: 84\n",
            "Loss: 0.8921875149775774| Acc: 72.92806243896484 (36405.6875/49920)\n",
            "Loss: 0.5720902076363563| Acc: 81.70999908447266 (8171/10000)\n",
            "\n",
            "Epoch: 85\n",
            "Loss: 0.8994770545225877| Acc: 72.55229187011719 (36218.1015625/49920)\n",
            "Loss: 0.5423145508766174| Acc: 82.54000091552734 (8254/10000)\n",
            "\n",
            "Epoch: 86\n",
            "Loss: 0.8755154750286005| Acc: 73.33688354492188 (36609.7734375/49920)\n",
            "Loss: 0.5374384993314743| Acc: 82.68000030517578 (8268/10000)\n",
            "\n",
            "Epoch: 87\n",
            "Loss: 0.8861949945107485| Acc: 73.00174713134766 (36442.47265625/49920)\n",
            "Loss: 0.5832940691709518| Acc: 81.5 (8150/10000)\n",
            "\n",
            "Epoch: 88\n",
            "Loss: 0.8941552342512669| Acc: 73.23973083496094 (36561.2734375/49920)\n",
            "Loss: 0.5794033068418503| Acc: 80.62999725341797 (8063/10000)\n",
            "\n",
            "Epoch: 89\n",
            "Loss: 0.9276189561073597| Acc: 71.7984619140625 (35841.79296875/49920)\n",
            "Loss: 0.526212956905365| Acc: 82.87000274658203 (8287/10000)\n",
            "\n",
            "Epoch: 90\n",
            "Loss: 0.8828173921658442| Acc: 73.26017761230469 (36571.48046875/49920)\n",
            "Loss: 0.5453201374411583| Acc: 83.2699966430664 (8327/10000)\n",
            "\n",
            "Epoch: 91\n",
            "Loss: 0.9393084244850355| Acc: 71.47099304199219 (35678.3203125/49920)\n",
            "Loss: 0.5692943891882897| Acc: 82.05000305175781 (8205/10000)\n",
            "\n",
            "Epoch: 92\n",
            "Loss: 0.909583010734656| Acc: 72.53857421875 (36211.2578125/49920)\n",
            "Loss: 0.5870547223091126| Acc: 81.01000213623047 (8101/10000)\n",
            "\n",
            "Epoch: 93\n",
            "Loss: 0.8802630537595504| Acc: 73.04976654052734 (36466.44140625/49920)\n",
            "Loss: 0.5199627497792244| Acc: 83.25 (8325/10000)\n",
            "\n",
            "Epoch: 94\n",
            "Loss: 0.8635568987100553| Acc: 73.89144897460938 (36886.61328125/49920)\n",
            "Loss: 0.528783447444439| Acc: 83.05000305175781 (8305/10000)\n",
            "\n",
            "Epoch: 95\n",
            "Loss: 0.9167737271541204| Acc: 72.0292739868164 (35957.01171875/49920)\n",
            "Loss: 0.5836840361356735| Acc: 81.31999969482422 (8132/10000)\n",
            "\n",
            "Epoch: 96\n",
            "Loss: 0.8277285163219158| Acc: 74.98526763916016 (37432.6484375/49920)\n",
            "Loss: 0.5547474494576454| Acc: 81.41000366210938 (8141/10000)\n",
            "\n",
            "Epoch: 97\n",
            "Loss: 0.881347634547796| Acc: 73.3433609008789 (36613.00390625/49920)\n",
            "Loss: 0.5404173165559769| Acc: 83.2699966430664 (8327/10000)\n",
            "\n",
            "Epoch: 98\n",
            "Loss: 0.8858722373461112| Acc: 73.2409896850586 (36561.90234375/49920)\n",
            "Loss: 0.5199320921301842| Acc: 83.62999725341797 (8363/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 99\n",
            "Loss: 0.8934355098467607| Acc: 72.55818939208984 (36221.05078125/49920)\n",
            "Loss: 0.6398050451278686| Acc: 79.25 (7925/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJCHkouWM-nU"
      },
      "source": [
        "# CutMix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mgehVKXNGBb"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np \n",
        "import csv\n",
        "from enum import Enum\n",
        "from segmix.models import Model, load_model, save_checkpoint, load_checkpoint\n",
        "from segmix.datasets import Dataset, getTransfroms, getDatasetLoaders\n",
        "from segmix.train import MixTrainer, MixTester\n",
        "from segmix.mix import CutMix\n",
        "from segmix.logger import CSVLogger\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEozzCfaNGBc",
        "outputId": "1d0a0505-28eb-4240-9973-1d9f06e115e2"
      },
      "source": [
        "def main(): \n",
        "    device = \"cuda\"\n",
        "    mpath = \"/content/drive/MyDrive/segmix/cutmix_resnet18_100.pth\"\n",
        "    logpath = \"/content/drive/MyDrive/segmix/cutmix_resnet18_100_log.csv\"\n",
        "    resume = os.path.exists(mpath)\n",
        "    dpath = \".\"\n",
        "    \n",
        "    model = load_model(Model.resnet18).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9, weight_decay=1e-4)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,78,eta_min=0.001)\n",
        "    mixmethod = CutMix(0.3, device)\n",
        "    epochs = 100\n",
        "    best_acc, s_epoch = 0, 0\n",
        "    \n",
        "    if resume: \n",
        "        print(\"Resuming from the last checkpoint...\")\n",
        "        model, optimizer, s_epoch, best_acc = load_checkpoint(mpath, model, optimizer)\n",
        "        print(s_epoch)\n",
        "        print(best_acc)\n",
        "\n",
        "    train_transforms, test_transforms = getTransfroms()\n",
        "    trainset, trainloader, testset, testloader, classes = getDatasetLoaders(Dataset.cifar10, dpath, train_transforms, test_transforms)\n",
        "    \n",
        "    trainer = MixTrainer(model, trainloader, criterion, optimizer, mixmethod, lr_scheduler=lr_scheduler, device=device)\n",
        "    tester = MixTester(model, criterion, testloader, device=device)\n",
        "    logger = CSVLogger(logpath, ['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n",
        "    \n",
        "    for epoch in range(s_epoch +  1, epochs):\n",
        "        train_loss, train_acc = trainer.train(epoch)\n",
        "        test_loss, test_acc = tester.test(epoch)\n",
        "        \n",
        "        if(test_acc > best_acc): \n",
        "            best_acc = test_acc\n",
        "            print(\"Saving...\")\n",
        "            save_checkpoint(model, mpath, optimizer, epoch, best_acc)\n",
        "            \n",
        "        logger.log([epoch, train_loss, train_acc, test_loss, test_acc])\n",
        "            \n",
        "if __name__ == \"__main__\": \n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 1\n",
            "Loss: 2.1954200212772075| Acc: 21.62127685546875 (10793.341796875/49920)\n",
            "Loss: 1.9373972523212433| Acc: 33.560001373291016 (3356/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "Loss: 2.022474565872779| Acc: 27.515466690063477 (13735.720703125/49920)\n",
            "Loss: 1.6690476047992706| Acc: 39.900001525878906 (3990/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 3\n",
            "Loss: 1.9677294670007168| Acc: 29.83542823791504 (14893.8466796875/49920)\n",
            "Loss: 1.7913320577144622| Acc: 40.33000183105469 (4033/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "Loss: 1.9373464021927271| Acc: 31.085969924926758 (15518.1162109375/49920)\n",
            "Loss: 2.0655963027477267| Acc: 40.689998626708984 (4069/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 5\n",
            "Loss: 1.9150375133905655| Acc: 32.44758605957031 (16197.8349609375/49920)\n",
            "Loss: 1.5625947630405426| Acc: 44.0 (4400/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 6\n",
            "Loss: 1.8629123473778748| Acc: 34.456947326660156 (17200.908203125/49920)\n",
            "Loss: 1.4139907944202423| Acc: 50.08000183105469 (5008/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 7\n",
            "Loss: 1.8359699664971767| Acc: 35.2766227722168 (17610.08984375/49920)\n",
            "Loss: 1.5164595544338226| Acc: 48.56999969482422 (4857/10000)\n",
            "\n",
            "Epoch: 8\n",
            "Loss: 1.8540395082571568| Acc: 35.31570816040039 (17629.6015625/49920)\n",
            "Loss: 1.886806263923645| Acc: 48.619998931884766 (4862/10000)\n",
            "\n",
            "Epoch: 9\n",
            "Loss: 1.7903337576450447| Acc: 38.00486373901367 (18972.02734375/49920)\n",
            "Loss: 1.339368976354599| Acc: 52.189998626708984 (5219/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 10\n",
            "Loss: 1.7596433688432742| Acc: 39.222084045410156 (19579.6640625/49920)\n",
            "Loss: 1.3648214542865753| Acc: 54.130001068115234 (5413/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 11\n",
            "Loss: 1.76667048564324| Acc: 39.1369514465332 (19537.166015625/49920)\n",
            "Loss: 1.2990364640951158| Acc: 57.7400016784668 (5774/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 12\n",
            "Loss: 1.6989134274996245| Acc: 41.33004379272461 (20631.95703125/49920)\n",
            "Loss: 1.3282782196998597| Acc: 55.88999938964844 (5589/10000)\n",
            "\n",
            "Epoch: 13\n",
            "Loss: 1.7164852924835987| Acc: 40.719947814941406 (20327.3984375/49920)\n",
            "Loss: 1.6419533860683442| Acc: 54.9900016784668 (5499/10000)\n",
            "\n",
            "Epoch: 14\n",
            "Loss: 1.6155592007514759| Acc: 44.42792510986328 (22178.419921875/49920)\n",
            "Loss: 1.129549897313118| Acc: 61.2599983215332 (6126/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "Loss: 1.6305222098643963| Acc: 44.17881774902344 (22054.064453125/49920)\n",
            "Loss: 1.1612203371524812| Acc: 62.54999923706055 (6255/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 16\n",
            "Loss: 1.6859634219071804| Acc: 42.08259201049805 (21007.630859375/49920)\n",
            "Loss: 1.522248799800873| Acc: 59.2599983215332 (5926/10000)\n",
            "\n",
            "Epoch: 17\n",
            "Loss: 1.5931287337572146| Acc: 45.63145446777344 (22779.22265625/49920)\n",
            "Loss: 1.1239030474424363| Acc: 64.66000366210938 (6466/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 18\n",
            "Loss: 1.6024546519303933| Acc: 45.360084533691406 (22643.755859375/49920)\n",
            "Loss: 1.073574783205986| Acc: 66.36000061035156 (6636/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 19\n",
            "Loss: 1.5677214714197012| Acc: 46.57748031616211 (23251.478515625/49920)\n",
            "Loss: 1.0831104022264482| Acc: 65.58000183105469 (6558/10000)\n",
            "\n",
            "Epoch: 20\n",
            "Loss: 1.5613668808570276| Acc: 47.03162384033203 (23478.1875/49920)\n",
            "Loss: 1.1207899194955826| Acc: 63.84000015258789 (6384/10000)\n",
            "\n",
            "Epoch: 21\n",
            "Loss: 1.6117605157387562| Acc: 44.953311920166016 (22440.69140625/49920)\n",
            "Loss: 1.1426476758718491| Acc: 62.529998779296875 (6253/10000)\n",
            "\n",
            "Epoch: 22\n",
            "Loss: 1.5517325511345497| Acc: 47.158077239990234 (23541.3125/49920)\n",
            "Loss: 0.9877532905340195| Acc: 68.16000366210938 (6816/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 23\n",
            "Loss: 1.5539107579451341| Acc: 46.84467315673828 (23384.859375/49920)\n",
            "Loss: 0.9912953978776932| Acc: 69.08999633789062 (6909/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 24\n",
            "Loss: 1.5141571589005298| Acc: 48.276336669921875 (24099.546875/49920)\n",
            "Loss: 1.2970290023088455| Acc: 63.77000045776367 (6377/10000)\n",
            "\n",
            "Epoch: 25\n",
            "Loss: 1.524603634614211| Acc: 48.33951950073242 (24131.087890625/49920)\n",
            "Loss: 1.0809858387708664| Acc: 68.05000305175781 (6805/10000)\n",
            "\n",
            "Epoch: 26\n",
            "Loss: 1.5149836900906686| Acc: 48.817848205566406 (24369.869140625/49920)\n",
            "Loss: 0.9008790278434753| Acc: 70.06999969482422 (7007/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 27\n",
            "Loss: 1.475899707354032| Acc: 50.148712158203125 (25034.236328125/49920)\n",
            "Loss: 0.8773832893371583| Acc: 70.5199966430664 (7052/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 28\n",
            "Loss: 1.4905191427622086| Acc: 49.54426193237305 (24732.49609375/49920)\n",
            "Loss: 1.0990998190641403| Acc: 64.2699966430664 (6427/10000)\n",
            "\n",
            "Epoch: 29\n",
            "Loss: 1.5142726910419952| Acc: 48.92781066894531 (24424.763671875/49920)\n",
            "Loss: 1.003551453948021| Acc: 68.44999694824219 (6845/10000)\n",
            "\n",
            "Epoch: 30\n",
            "Loss: 1.4656708234395737| Acc: 50.60347366333008 (25261.25390625/49920)\n",
            "Loss: 0.8324127858877182| Acc: 72.26000213623047 (7226/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 31\n",
            "Loss: 1.4828168743695969| Acc: 49.70439529418945 (24812.435546875/49920)\n",
            "Loss: 0.8787908530235291| Acc: 72.05999755859375 (7206/10000)\n",
            "\n",
            "Epoch: 32\n",
            "Loss: 1.45420946371861| Acc: 50.645713806152344 (25282.33984375/49920)\n",
            "Loss: 0.9438031136989593| Acc: 68.80999755859375 (6881/10000)\n",
            "\n",
            "Epoch: 33\n",
            "Loss: 1.440503274477445| Acc: 51.315216064453125 (25616.5546875/49920)\n",
            "Loss: 0.9285091722011566| Acc: 71.05000305175781 (7105/10000)\n",
            "\n",
            "Epoch: 34\n",
            "Loss: 1.4453832320677928| Acc: 51.3297233581543 (25623.796875/49920)\n",
            "Loss: 0.8330326980352402| Acc: 73.4800033569336 (7348/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 35\n",
            "Loss: 1.4055986086527505| Acc: 52.740806579589844 (26328.2109375/49920)\n",
            "Loss: 0.8097879248857498| Acc: 73.13999938964844 (7314/10000)\n",
            "\n",
            "Epoch: 36\n",
            "Loss: 1.4206094191624568| Acc: 52.175376892089844 (26045.947265625/49920)\n",
            "Loss: 1.107981355190277| Acc: 67.66999816894531 (6767/10000)\n",
            "\n",
            "Epoch: 37\n",
            "Loss: 1.4506687800089517| Acc: 51.3387565612793 (25628.30859375/49920)\n",
            "Loss: 1.001550977230072| Acc: 69.08000183105469 (6908/10000)\n",
            "\n",
            "Epoch: 38\n",
            "Loss: 1.3931706835062077| Acc: 52.85903549194336 (26387.23046875/49920)\n",
            "Loss: 0.7765717726945877| Acc: 75.05999755859375 (7506/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 39\n",
            "Loss: 1.4035725673039754| Acc: 52.74481201171875 (26330.208984375/49920)\n",
            "Loss: 0.8001965445280075| Acc: 74.5199966430664 (7452/10000)\n",
            "\n",
            "Epoch: 40\n",
            "Loss: 1.4611717688731658| Acc: 50.813880920410156 (25366.2890625/49920)\n",
            "Loss: 0.9409504336118698| Acc: 71.27999877929688 (7128/10000)\n",
            "\n",
            "Epoch: 41\n",
            "Loss: 1.4311308714059683| Acc: 52.12004089355469 (26018.32421875/49920)\n",
            "Loss: 1.0540012991428376| Acc: 70.19999694824219 (7020/10000)\n",
            "\n",
            "Epoch: 42\n",
            "Loss: 1.4213916592108897| Acc: 52.149322509765625 (26032.943359375/49920)\n",
            "Loss: 0.7410565811395645| Acc: 76.1500015258789 (7615/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 43\n",
            "Loss: 1.4023984416937216| Acc: 53.0679931640625 (26491.54296875/49920)\n",
            "Loss: 0.7528624528646469| Acc: 75.55000305175781 (7555/10000)\n",
            "\n",
            "Epoch: 44\n",
            "Loss: 1.3919602806751545| Acc: 53.256248474121094 (26585.51953125/49920)\n",
            "Loss: 0.9232790410518646| Acc: 69.54000091552734 (6954/10000)\n",
            "\n",
            "Epoch: 45\n",
            "Loss: 1.4062063975211903| Acc: 52.62291717529297 (26269.359375/49920)\n",
            "Loss: 0.8188330733776092| Acc: 73.18000030517578 (7318/10000)\n",
            "\n",
            "Epoch: 46\n",
            "Loss: 1.3923061969952706| Acc: 53.137210845947266 (26526.095703125/49920)\n",
            "Loss: 0.7763448262214661| Acc: 76.52999877929688 (7653/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 47\n",
            "Loss: 1.439130135377248| Acc: 51.913211822509766 (25915.07421875/49920)\n",
            "Loss: 0.7734120446443558| Acc: 75.33000183105469 (7533/10000)\n",
            "\n",
            "Epoch: 48\n",
            "Loss: 1.384909044779264| Acc: 53.88048553466797 (26897.138671875/49920)\n",
            "Loss: 0.8613096088171005| Acc: 72.94000244140625 (7294/10000)\n",
            "\n",
            "Epoch: 49\n",
            "Loss: 1.350548367928236| Acc: 54.88156509399414 (27396.876953125/49920)\n",
            "Loss: 0.8826380121707916| Acc: 72.83999633789062 (7284/10000)\n",
            "\n",
            "Epoch: 50\n",
            "Loss: 1.3106302019877312| Acc: 56.273193359375 (28091.578125/49920)\n",
            "Loss: 0.695229926109314| Acc: 77.7300033569336 (7773/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 51\n",
            "Loss: 1.3436212554956093| Acc: 54.7677116394043 (27340.04296875/49920)\n",
            "Loss: 0.7128697964549064| Acc: 77.20999908447266 (7721/10000)\n",
            "\n",
            "Epoch: 52\n",
            "Loss: 1.3419498697305337| Acc: 55.354400634765625 (27632.91796875/49920)\n",
            "Loss: 0.8036114549636841| Acc: 73.77999877929688 (7378/10000)\n",
            "\n",
            "Epoch: 53\n",
            "Loss: 1.3592519607299414| Acc: 54.131752014160156 (27022.5703125/49920)\n",
            "Loss: 0.8203459864854813| Acc: 72.58999633789062 (7259/10000)\n",
            "\n",
            "Epoch: 54\n",
            "Loss: 1.3761936224423923| Acc: 54.06877136230469 (26991.130859375/49920)\n",
            "Loss: 0.6966873568296432| Acc: 78.37000274658203 (7837/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 55\n",
            "Loss: 1.3749837303772952| Acc: 53.83346176147461 (26873.6640625/49920)\n",
            "Loss: 0.6992656481266022| Acc: 77.5199966430664 (7752/10000)\n",
            "\n",
            "Epoch: 56\n",
            "Loss: 1.350142384492434| Acc: 55.026058197021484 (27469.0078125/49920)\n",
            "Loss: 0.8407415813207626| Acc: 73.58999633789062 (7359/10000)\n",
            "\n",
            "Epoch: 57\n",
            "Loss: 1.37458476852148| Acc: 53.89371109008789 (26903.740234375/49920)\n",
            "Loss: 0.7086962172389031| Acc: 77.05999755859375 (7706/10000)\n",
            "\n",
            "Epoch: 58\n",
            "Loss: 1.3436107164774185| Acc: 55.260231018066406 (27585.908203125/49920)\n",
            "Loss: 0.6723360875248909| Acc: 78.5999984741211 (7860/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 59\n",
            "Loss: 1.3638866366484226| Acc: 54.41896438598633 (27165.947265625/49920)\n",
            "Loss: 0.7273734492063523| Acc: 78.13999938964844 (7814/10000)\n",
            "\n",
            "Epoch: 60\n",
            "Loss: 1.3750124585934174| Acc: 54.04343795776367 (26978.484375/49920)\n",
            "Loss: 0.7991292977333069| Acc: 75.47000122070312 (7547/10000)\n",
            "\n",
            "Epoch: 61\n",
            "Loss: 1.361849613678761| Acc: 54.43122482299805 (27172.06640625/49920)\n",
            "Loss: 0.7575839680433273| Acc: 76.4000015258789 (7640/10000)\n",
            "\n",
            "Epoch: 62\n",
            "Loss: 1.2563267234044198| Acc: 58.519596099853516 (29212.982421875/49920)\n",
            "Loss: 0.630507940351963| Acc: 79.16999816894531 (7917/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 63\n",
            "Loss: 1.2777210605450167| Acc: 57.69057083129883 (28799.1328125/49920)\n",
            "Loss: 0.6627429673075675| Acc: 78.9000015258789 (7890/10000)\n",
            "\n",
            "Epoch: 64\n",
            "Loss: 1.3178192575772603| Acc: 56.13275146484375 (28021.46875/49920)\n",
            "Loss: 0.820711201429367| Acc: 74.80999755859375 (7481/10000)\n",
            "\n",
            "Epoch: 65\n",
            "Loss: 1.3401684482892355| Acc: 55.14771270751953 (27529.73828125/49920)\n",
            "Loss: 0.7995719861984253| Acc: 74.75 (7475/10000)\n",
            "\n",
            "Epoch: 66\n",
            "Loss: 1.2887269637523553| Acc: 57.59523391723633 (28751.541015625/49920)\n",
            "Loss: 0.6309127366542816| Acc: 80.4000015258789 (8040/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 67\n",
            "Loss: 1.3191237902029966| Acc: 56.01264572143555 (27961.51171875/49920)\n",
            "Loss: 0.7724281638860703| Acc: 75.76000213623047 (7576/10000)\n",
            "\n",
            "Epoch: 68\n",
            "Loss: 1.2923932656263695| Acc: 57.198726654052734 (28553.60546875/49920)\n",
            "Loss: 0.8600088489055634| Acc: 71.68000030517578 (7168/10000)\n",
            "\n",
            "Epoch: 69\n",
            "Loss: 1.3016923337410657| Acc: 56.432132720947266 (28170.919921875/49920)\n",
            "Loss: 0.7212752598524094| Acc: 77.30999755859375 (7731/10000)\n",
            "\n",
            "Epoch: 70\n",
            "Loss: 1.3227020064989725| Acc: 55.79307556152344 (27851.90234375/49920)\n",
            "Loss: 0.6476422762870788| Acc: 79.66999816894531 (7967/10000)\n",
            "\n",
            "Epoch: 71\n",
            "Loss: 1.3172670104564765| Acc: 55.87936019897461 (27894.978515625/49920)\n",
            "Loss: 0.6429449769854546| Acc: 79.88999938964844 (7989/10000)\n",
            "\n",
            "Epoch: 72\n",
            "Loss: 1.2636910119117835| Acc: 57.84724044799805 (28877.341796875/49920)\n",
            "Loss: 0.790198193192482| Acc: 74.94999694824219 (7495/10000)\n",
            "\n",
            "Epoch: 73\n",
            "Loss: 1.3124540231166741| Acc: 56.37178039550781 (28140.79296875/49920)\n",
            "Loss: 0.7726959800720214| Acc: 75.55000305175781 (7555/10000)\n",
            "\n",
            "Epoch: 74\n",
            "Loss: 1.304094026486079| Acc: 56.64886474609375 (28279.11328125/49920)\n",
            "Loss: 0.6383645805716515| Acc: 80.43000030517578 (8043/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 75\n",
            "Loss: 1.2969612337075747| Acc: 56.697078704833984 (28303.18359375/49920)\n",
            "Loss: 0.6646261170506478| Acc: 79.55999755859375 (7956/10000)\n",
            "\n",
            "Epoch: 76\n",
            "Loss: 1.3294362872074812| Acc: 55.65168762207031 (27781.322265625/49920)\n",
            "Loss: 0.7793571317195892| Acc: 76.0199966430664 (7602/10000)\n",
            "\n",
            "Epoch: 77\n",
            "Loss: 1.3097804570809388| Acc: 56.62623596191406 (28267.81640625/49920)\n",
            "Loss: 0.6836021411418914| Acc: 78.66999816894531 (7867/10000)\n",
            "\n",
            "Epoch: 78\n",
            "Loss: 1.3028778120493278| Acc: 56.695011138916016 (28302.150390625/49920)\n",
            "Loss: 0.6256630915403366| Acc: 80.44999694824219 (8045/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 79\n",
            "Loss: 1.3175627787907918| Acc: 56.257728576660156 (28083.857421875/49920)\n",
            "Loss: 0.6381879729032517| Acc: 80.26000213623047 (8026/10000)\n",
            "\n",
            "Epoch: 80\n",
            "Loss: 1.285610863031485| Acc: 57.707820892333984 (28807.74609375/49920)\n",
            "Loss: 0.7300637441873551| Acc: 77.98999786376953 (7799/10000)\n",
            "\n",
            "Epoch: 81\n",
            "Loss: 1.2763447277056865| Acc: 57.368247985839844 (28638.23046875/49920)\n",
            "Loss: 0.6495537745952606| Acc: 79.3499984741211 (7935/10000)\n",
            "\n",
            "Epoch: 82\n",
            "Loss: 1.2610888016529573| Acc: 58.07347869873047 (28990.279296875/49920)\n",
            "Loss: 0.6650103294849395| Acc: 80.33999633789062 (8034/10000)\n",
            "\n",
            "Epoch: 83\n",
            "Loss: 1.2897229697459782| Acc: 57.355628967285156 (28631.9296875/49920)\n",
            "Loss: 0.6079858586192131| Acc: 80.43000030517578 (8043/10000)\n",
            "\n",
            "Epoch: 84\n",
            "Loss: 1.2381516262506826| Acc: 58.85468673706055 (29380.259765625/49920)\n",
            "Loss: 0.7194442087411881| Acc: 77.37999725341797 (7738/10000)\n",
            "\n",
            "Epoch: 85\n",
            "Loss: 1.2573100397220025| Acc: 58.11962127685547 (29013.314453125/49920)\n",
            "Loss: 0.6846518939733506| Acc: 79.05000305175781 (7905/10000)\n",
            "\n",
            "Epoch: 86\n",
            "Loss: 1.2457681548901094| Acc: 58.594058990478516 (29250.15625/49920)\n",
            "Loss: 0.6014140811562538| Acc: 81.5999984741211 (8160/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 87\n",
            "Loss: 1.3112897331898028| Acc: 55.69841384887695 (27804.646484375/49920)\n",
            "Loss: 0.5875807401537895| Acc: 81.2300033569336 (8123/10000)\n",
            "\n",
            "Epoch: 88\n",
            "Loss: 1.2601316702671541| Acc: 57.7169189453125 (28812.28515625/49920)\n",
            "Loss: 0.691633839905262| Acc: 77.3499984741211 (7735/10000)\n",
            "\n",
            "Epoch: 89\n",
            "Loss: 1.2800962244852996| Acc: 57.70880889892578 (28808.23828125/49920)\n",
            "Loss: 0.611462966799736| Acc: 81.2699966430664 (8127/10000)\n",
            "\n",
            "Epoch: 90\n",
            "Loss: 1.2741037162450644| Acc: 57.8461799621582 (28876.8125/49920)\n",
            "Loss: 0.5809805956482887| Acc: 81.30000305175781 (8130/10000)\n",
            "\n",
            "Epoch: 91\n",
            "Loss: 1.2694141655396192| Acc: 57.818519592285156 (28863.00390625/49920)\n",
            "Loss: 0.6191179212927819| Acc: 81.1500015258789 (8115/10000)\n",
            "\n",
            "Epoch: 92\n",
            "Loss: 1.265153728540127| Acc: 58.50033950805664 (29203.37109375/49920)\n",
            "Loss: 0.7474640375375747| Acc: 75.48999786376953 (7549/10000)\n",
            "\n",
            "Epoch: 93\n",
            "Loss: 1.2678502578001756| Acc: 58.201683044433594 (29054.28125/49920)\n",
            "Loss: 0.6466419327259064| Acc: 80.45999908447266 (8046/10000)\n",
            "\n",
            "Epoch: 94\n",
            "Loss: 1.230152717156288| Acc: 59.49081039428711 (29697.8125/49920)\n",
            "Loss: 0.5664800575375557| Acc: 82.41000366210938 (8241/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 95\n",
            "Loss: 1.2183918728278234| Acc: 59.39605712890625 (29650.51171875/49920)\n",
            "Loss: 0.5772597786784172| Acc: 81.94000244140625 (8194/10000)\n",
            "\n",
            "Epoch: 96\n",
            "Loss: 1.2359389121715838| Acc: 59.0048942565918 (29455.2421875/49920)\n",
            "Loss: 0.6816292253136634| Acc: 77.31999969482422 (7732/10000)\n",
            "\n",
            "Epoch: 97\n",
            "Loss: 1.2634621453590882| Acc: 58.0405158996582 (28973.82421875/49920)\n",
            "Loss: 0.635331609249115| Acc: 79.7699966430664 (7977/10000)\n",
            "\n",
            "Epoch: 98\n",
            "Loss: 1.2504802123094216| Acc: 58.826637268066406 (29366.2578125/49920)\n",
            "Loss: 0.577992752790451| Acc: 82.38999938964844 (8239/10000)\n",
            "\n",
            "Epoch: 99\n",
            "Loss: 1.2384957742996705| Acc: 59.07378387451172 (29489.6328125/49920)\n",
            "Loss: 0.5755047485232353| Acc: 81.69999694824219 (8170/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW3c_y7HxpQV"
      },
      "source": [
        "# Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHNMl2PX1A1q"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet18\n",
        "import numpy as np \n",
        "import csv\n",
        "from enum import Enum\n",
        "from segmix.models import Model, load_model, save_checkpoint, load_checkpoint\n",
        "from segmix.datasets import Dataset, getTransfroms, getDatasetLoaders\n",
        "from segmix.train import MixTrainer, MixTester\n",
        "from segmix.mix import Cifar10Segmix\n",
        "from segmix.logger import CSVLogger\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIf1By6jkIbx"
      },
      "source": [
        "segpath = \"/content/drive/MyDrive/segmentCutMix/segment.pth\"\n",
        "segmodel = load_model(Model.resnet18_modified).to(\"cuda\")\n",
        "checkpoint = torch.load(segpath)\n",
        "segmodel.load_state_dict(checkpoint[\"state\"])\n",
        "mixmethod = Cifar10Segmix(segmodel, 0.3, \"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFVy9VEwxvSX",
        "outputId": "d5c7e0c8-e35b-46ad-9bf1-c2fa6ff6b8d1"
      },
      "source": [
        "train_transforms, test_transforms = getTransfroms()\n",
        "trainset, trainloader, testset, testloader, classes = getDatasetLoaders(Dataset.cifar10, \".\", train_transforms, test_transforms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbcVfZuW4M1O"
      },
      "source": [
        "def attention(x):\n",
        "  return torch.sigmoid(torch.logsumexp(x, 1, keepdim=True))\n",
        "    \n",
        "def get_segmented_images(x):\n",
        "  preds = segmodel(x.to(\"cuda\"))\n",
        "  attn = attention(preds)\n",
        "  attn = torch.cat((attn, attn, attn), dim=1)\n",
        "  attn[attn < 0.3] = 0.0\n",
        "  attn[attn >= 0.3] = 1.0\n",
        "  x = x.to(\"cuda\") * attn.to(\"cuda\")\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ0KdBUR2Ndb"
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "\n",
        "inp, out = iter(trainloader).next()\n",
        "segmented = get_segmented_images(inp)\n",
        "\n",
        "print(segmented.size())\n",
        "plt.imshow(segmented[56].detach().cpu().numpy().transpose(1, 2, 0) * 0.2023 + 0.48)\n",
        "print(out[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vsd9esAe25-F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsRJVIGFMdi0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5Xo57YnMrCr"
      },
      "source": [
        "# Double Segmix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCBuFfndMxcx",
        "outputId": "92cee525-9ca2-4acc-bdef-7c965f683f03"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQOL-qGvMxc2",
        "outputId": "28e4a13d-f851-4cdb-f00e-7bd75f493374"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: MohamedAlmaki\n",
            "Password: ··········\n",
            "Repo name: segmix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Lh55K9Mxc4",
        "outputId": "23be3b2c-ef8b-4141-c236-1b69c2f1c7b9"
      },
      "source": [
        "! python --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkCXSgJ9A4sV",
        "outputId": "bd7c24c4-a15c-4076-8056-840a64897d3c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMw0NL9_Mxc7"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np \n",
        "import csv\n",
        "from enum import Enum\n",
        "from segmix.models import Model, load_model, save_checkpoint, load_checkpoint\n",
        "from segmix.datasets import Dataset, getTransfroms, getDatasetLoaders\n",
        "from segmix.train import MixTrainer, MixTester, DoubleMixTrainer\n",
        "from segmix.mix import Cifar10DoubleSegmix\n",
        "from segmix.logger import CSVLogger\n",
        "import os "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLg1mkYiMxc9",
        "outputId": "083f3819-a4f9-42c8-ff25-61b9a2439f9e"
      },
      "source": [
        "device = \"cuda\"\n",
        "mpath = \"/content/drive/MyDrive/segmix/doublesegmix_resnet18_pretrained_100.pth\"\n",
        "segpath = \"/content/drive/MyDrive/segmentCutMix/segment.pth\"\n",
        "logpath = \"/content/drive/MyDrive/segmix/doublesegmix_resnet18_pretrained_100_log.csv\"\n",
        "resume = os.path.exists(mpath)\n",
        "dpath = \".\"\n",
        "\n",
        "model = load_model(Model.resnet18, pretrained=True).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9, weight_decay=1e-4)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 78, eta_min=0.001)\n",
        "epochs = 100\n",
        "best_acc, s_epoch = 0, 0\n",
        "\n",
        "segmodel = load_model(Model.resnet18_modified).to(device)\n",
        "checkpoint = torch.load(segpath)\n",
        "segmodel.load_state_dict(checkpoint[\"state\"])\n",
        "mixmethod = Cifar10DoubleSegmix(segmodel, 0.3, device)\n",
        "\n",
        "if resume: \n",
        "    print(\"Resuming from the last checkpoint...\")\n",
        "    model, optimizer, s_epoch, best_acc = load_checkpoint(mpath, model, optimizer)\n",
        "    print(s_epoch)\n",
        "    print(best_acc)\n",
        "\n",
        "train_transforms, test_transforms = getTransfroms()\n",
        "trainset, trainloader, testset, testloader, classes = getDatasetLoaders(Dataset.cifar10, dpath, train_transforms, test_transforms)\n",
        "\n",
        "trainer = DoubleMixTrainer(model, trainloader, criterion, optimizer, mixmethod, lr_scheduler=lr_scheduler, device=device)\n",
        "tester = MixTester(model, criterion, testloader, device=device)\n",
        "logger = CSVLogger(logpath, ['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n",
        "\n",
        "for epoch in range(s_epoch +  1, epochs):\n",
        "    train_loss, train_acc = trainer.train(epoch)\n",
        "    test_loss, test_acc = tester.test(epoch)\n",
        "    \n",
        "    if(test_acc > best_acc): \n",
        "        best_acc = test_acc\n",
        "        print(\"Saving...\")\n",
        "        save_checkpoint(model, mpath, optimizer, epoch, best_acc)\n",
        "        \n",
        "    logger.log([epoch, train_loss, train_acc, test_loss, test_acc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "Epoch: 1\n",
            "Loss: 1.6778759870773707| Acc: 43.48663330078125 (21708.52734375/49920)\n",
            "Loss: 1.3218396663665772| Acc: 58.560001373291016 (5856/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 2\n",
            "Loss: 1.402284607826135| Acc: 54.970909118652344 (27441.4765625/49920)\n",
            "Loss: 0.9088656544685364| Acc: 70.20999908447266 (7021/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 3\n",
            "Loss: 1.3396087582294758| Acc: 57.691070556640625 (28799.3828125/49920)\n",
            "Loss: 0.8537084919214248| Acc: 72.19000244140625 (7219/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 4\n",
            "Loss: 1.325685727596283| Acc: 58.17253112792969 (29039.728515625/49920)\n",
            "Loss: 0.9943580538034439| Acc: 68.19000244140625 (6819/10000)\n",
            "\n",
            "Epoch: 5\n",
            "Loss: 1.3257609883944192| Acc: 58.32551956176758 (29116.099609375/49920)\n",
            "Loss: 0.8401908135414123| Acc: 72.22000122070312 (7222/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 6\n",
            "Loss: 1.233173662882585| Acc: 61.45346450805664 (30677.5703125/49920)\n",
            "Loss: 0.7528441196680069| Acc: 75.77999877929688 (7578/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 7\n",
            "Loss: 1.2623752135496873| Acc: 60.52573776245117 (30214.447265625/49920)\n",
            "Loss: 0.8188834595680237| Acc: 74.97000122070312 (7497/10000)\n",
            "\n",
            "Epoch: 8\n",
            "Loss: 1.1906182365539746| Acc: 62.919681549072266 (31409.505859375/49920)\n",
            "Loss: 0.8554908084869385| Acc: 72.41999816894531 (7242/10000)\n",
            "\n",
            "Epoch: 9\n",
            "Loss: 1.2127979880724198| Acc: 62.07311248779297 (30986.8984375/49920)\n",
            "Loss: 0.8234785598516464| Acc: 74.41000366210938 (7441/10000)\n",
            "\n",
            "Epoch: 10\n",
            "Loss: 1.1501780702517583| Acc: 64.1224136352539 (32009.91015625/49920)\n",
            "Loss: 0.6984152615070343| Acc: 77.16000366210938 (7716/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 11\n",
            "Loss: 1.110500681705964| Acc: 65.3277359008789 (32611.607421875/49920)\n",
            "Loss: 0.9652458155155181| Acc: 68.62999725341797 (6863/10000)\n",
            "\n",
            "Epoch: 12\n",
            "Loss: 1.1813284253462768| Acc: 62.95584487915039 (31427.55859375/49920)\n",
            "Loss: 0.807203414440155| Acc: 72.58999633789062 (7259/10000)\n",
            "\n",
            "Epoch: 13\n",
            "Loss: 1.1317924878536127| Acc: 64.24720001220703 (32072.203125/49920)\n",
            "Loss: 0.727716515660286| Acc: 76.56999969482422 (7657/10000)\n",
            "\n",
            "Epoch: 14\n",
            "Loss: 1.082235631881616| Acc: 66.36576843261719 (33129.7890625/49920)\n",
            "Loss: 0.6762048834562302| Acc: 79.01000213623047 (7901/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 15\n",
            "Loss: 1.1881185742524953| Acc: 62.085105895996094 (30992.884765625/49920)\n",
            "Loss: 0.7937150990962982| Acc: 73.8499984741211 (7385/10000)\n",
            "\n",
            "Epoch: 16\n",
            "Loss: 1.1717761534910935| Acc: 63.2401008605957 (31569.45703125/49920)\n",
            "Loss: 0.7070793896913529| Acc: 76.9000015258789 (7690/10000)\n",
            "\n",
            "Epoch: 17\n",
            "Loss: 1.050602656450027| Acc: 67.34343719482422 (33617.84375/49920)\n",
            "Loss: 0.6967340725660324| Acc: 76.66999816894531 (7667/10000)\n",
            "\n",
            "Epoch: 18\n",
            "Loss: 1.1074378380408654| Acc: 65.3907699584961 (32643.072265625/49920)\n",
            "Loss: 0.6280858984589577| Acc: 79.6500015258789 (7965/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 19\n",
            "Loss: 1.12087543346943| Acc: 65.24826049804688 (32571.931640625/49920)\n",
            "Loss: 0.6162210661172867| Acc: 79.77999877929688 (7978/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 20\n",
            "Loss: 1.0357327183087668| Acc: 68.01142120361328 (33951.30078125/49920)\n",
            "Loss: 0.7165768650174141| Acc: 76.2300033569336 (7623/10000)\n",
            "\n",
            "Epoch: 21\n",
            "Loss: 1.1082902889985304| Acc: 65.38116455078125 (32638.27734375/49920)\n",
            "Loss: 0.7151363879442215| Acc: 77.27999877929688 (7728/10000)\n",
            "\n",
            "Epoch: 22\n",
            "Loss: 1.0503910156396719| Acc: 67.52571105957031 (33708.8359375/49920)\n",
            "Loss: 0.6314439836144448| Acc: 80.55000305175781 (8055/10000)\n",
            "Saving...\n",
            "\n",
            "Epoch: 23\n",
            "Loss: 1.0744417752975073| Acc: 66.30152893066406 (33097.72265625/49920)\n",
            "Loss: 0.6641056615114213| Acc: 79.48999786376953 (7949/10000)\n",
            "\n",
            "Epoch: 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caLV12DVNnXZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}